# PromptGrep

# ğŸ“œ README: Semgrep Rules for LLM Prompt Injection Detection

## ğŸ¯ Objective

These Semgrep rules aim to **detect potential prompt injection vulnerabilities** in Python projects that use Large Language Models (LLMs).

They focus on finding **places where untrusted user input (like web request parameters) is directly or indirectly passed into LLM prompts or generation calls**.

Prompt injection is a critical security issue in LLM-based apps. If an attacker can influence the prompt without proper sanitization, they can subvert or exfiltrate data from the model.

---

## ğŸ“¦ Rule Types

This repo includes:

âœ… **Heuristic Rules (pattern-based):**  
Detect common ways of building prompts unsafely using string interpolation, concatenation, `.format`, JSON templates, etc.

âœ… **Sink-based Rules:**  
Flag calls to LLM methods like `predict`, `invoke`, `generate`, `ask`, etc. using potentially tainted data.

âœ… **Taint Analysis Rules:**  
Track data flow from user-controlled sources (like `request.get_json()`) to LLM calls.

---

## âš™ï¸ Setup

1ï¸âƒ£ **Install Semgrep**

If you havenâ€™t already:

```bash
pip install semgrep
